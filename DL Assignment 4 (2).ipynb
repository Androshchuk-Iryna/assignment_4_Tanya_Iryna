{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":120777,"databundleVersionId":14442495,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:36:30.437038Z","iopub.execute_input":"2025-12-09T11:36:30.437655Z","iopub.status.idle":"2025-12-09T11:36:30.709123Z","shell.execute_reply.started":"2025-12-09T11:36:30.437629Z","shell.execute_reply":"2025-12-09T11:36:30.708289Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/kse-ua-location-extraction-2025/ru_geo_dataset.csv\n/kaggle/input/kse-ua-location-extraction-2025/README.md\n/kaggle/input/kse-ua-location-extraction-2025/labeling_sample.csv\n/kaggle/input/kse-ua-location-extraction-2025/test.csv\n/kaggle/input/kse-ua-location-extraction-2025/uk_geo_dataset.csv\n/kaggle/input/kse-ua-location-extraction-2025/uk_geo_dataset_processed_v1.parquet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"uk_data = pd.read_csv('/kaggle/input/kse-ua-location-extraction-2025/uk_geo_dataset.csv')\n#other_data = pd.read_csv('/kaggle/input/kse-ua-location-extraction-2025/ru_geo_dataset.csv')\nlabeling_sample = pd.read_csv('/kaggle/input/kse-ua-location-extraction-2025/labeling_sample.csv')\ntest_data = pd.read_csv('/kaggle/input/kse-ua-location-extraction-2025/test.csv')\nuk_geo_dataset = pd.read_parquet('/kaggle/input/kse-ua-location-extraction-2025/uk_geo_dataset_processed_v1.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:36:33.750748Z","iopub.execute_input":"2025-12-09T11:36:33.751117Z","iopub.status.idle":"2025-12-09T11:36:42.493348Z","shell.execute_reply.started":"2025-12-09T11:36:33.751097Z","shell.execute_reply":"2025-12-09T11:36:42.492549Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# print(uk_geo_dataset.head())\nprint(\"Сolumns\", uk_geo_dataset.columns.tolist())\nprint(uk_geo_dataset.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:36:42.494612Z","iopub.execute_input":"2025-12-09T11:36:42.494808Z","iopub.status.idle":"2025-12-09T11:36:42.500276Z","shell.execute_reply.started":"2025-12-09T11:36:42.494788Z","shell.execute_reply":"2025-12-09T11:36:42.499729Z"}},"outputs":[{"name":"stdout","text":"Сolumns ['tokens', 'labels', 'is_valid']\ntokens      object\nlabels      object\nis_valid     int64\ndtype: object\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# print(uk_data.head())\n# print(\"Сolumns\", uk_data.columns.tolist())\n# print(uk_data.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:47:12.210967Z","iopub.execute_input":"2025-12-09T08:47:12.211381Z","iopub.status.idle":"2025-12-09T08:47:12.231309Z","shell.execute_reply.started":"2025-12-09T08:47:12.211350Z","shell.execute_reply":"2025-12-09T08:47:12.230558Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# print(uk_geo_dataset.head())\n# print(\"Сolumns\", uk_geo_dataset.columns.tolist())\n# print(uk_geo_dataset.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:47:12.232249Z","iopub.execute_input":"2025-12-09T08:47:12.232537Z","iopub.status.idle":"2025-12-09T08:47:12.247684Z","shell.execute_reply.started":"2025-12-09T08:47:12.232495Z","shell.execute_reply":"2025-12-09T08:47:12.246914Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"uk_data['loc_markers'] = uk_data['loc_markers'].apply(eval)\nuk_data['num_locs'] = uk_data['loc_markers'].apply(len)\nuk_data['has_loc'] = uk_data['num_locs'] > 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:36:42.501111Z","iopub.execute_input":"2025-12-09T11:36:42.502302Z","iopub.status.idle":"2025-12-09T11:36:49.703128Z","shell.execute_reply.started":"2025-12-09T11:36:42.502282Z","shell.execute_reply":"2025-12-09T11:36:49.702421Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(f\"With loc: {uk_data['has_loc'].sum()} ({uk_data['has_loc'].mean()*100:.1f}%)\")\nprint(f\"Without loc: {(~uk_data['has_loc']).sum()} ({(~uk_data['has_loc']).mean()*100:.1f}%)\")\n\nuk_data['words'] = uk_data['text'].str.split().str.len()\nprint(f\"Average length: {uk_data['words'].mean():.1f} words\")\n\n\nprint(\"Excample:\")\nfor i in range(5):\n    row = uk_data[uk_data['has_loc']].iloc[i]\n    locs = [row['text'][s:e] for s,e in row['loc_markers']]\n    print(f\"\\n{row['text'][:60]}...\")\n    print(f\"> {locs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:36:49.704611Z","iopub.execute_input":"2025-12-09T11:36:49.705057Z","iopub.status.idle":"2025-12-09T11:36:53.487572Z","shell.execute_reply.started":"2025-12-09T11:36:49.705037Z","shell.execute_reply":"2025-12-09T11:36:53.486888Z"}},"outputs":[{"name":"stdout","text":"With loc: 233421 (23.1%)\nWithout loc: 776579 (76.9%)\nAverage length: 14.6 words\nExcample:\n\nПодібні розіграші проводили в Великій Британії....\n> ['Великій Британії']\n\nУ Львові 34-річний мешканець Яворівського району під час к...\n> ['Львові', 'Яворівського району']\n\nНагадаємо, президент України Володимир Зеленський скликав по...\n> ['України']\n\nСлід зауважити, що протягом останнього часу в пунктах пропус...\n> ['України', 'Білорусі']\n\nТим часом, О.Паращій вважає, що зміна глави Мінфіну навряд ч...\n> ['України']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n# uk_data['num_locs'].value_counts().head(6).sort_index().plot(kind='bar', ax=axes[0], color='teal')\n# axes[0].set_title('Number of locations in text')\n\n# uk_data['words'].hist(bins=30, ax=axes[1], color='salmon')\n# axes[1].set_title('Lenth of text (words)')\n# axes[1].set_xlim(0, 50)\n# axes[1].grid(False)\n\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:47:25.566864Z","iopub.execute_input":"2025-12-09T08:47:25.567120Z","iopub.status.idle":"2025-12-09T08:47:25.571035Z","shell.execute_reply.started":"2025-12-09T08:47:25.567099Z","shell.execute_reply":"2025-12-09T08:47:25.570250Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Analyze the proposed target metric","metadata":{}},{"cell_type":"markdown","source":"The competition uses **entity-level F1-score**, where each entity is a text span (start, end).\nThe model receives a score of 1 only when it has completely correctly restored the location boundaries.\nPartial matches (for example, finding “Львів” instead of “місто Львів”) are counted as errors.\n\n**Advantages:**\n\n* A classic approach to NER, consistent with standards (CoNLL, spaCy).\n* Clearly penalizes incorrect boundaries, which encourages high-quality sequence labeling.\n* Stable and understandable metric for comparing models.\n\n**Disadvantages:**\n\n* Complete dependence on exact span boundaries: even a 1-character offset = 0 points.\n* Does not take partial information into account - a model that “almost guessed right” gets the same score as a model that missed completely.\n* Very sensitive to tokenization (Byte Pair Encoding can cut names into components -> F1 drop).\n\n**Edge cases:**\n\n* Complex toponyms such as “Яворівського району” may have different segmentations -> risk of incorrect boundaries.\n* Locations with declension (Львів/Львові/Львова) - the model may consider them different tokens.\n* Several locations in a sentence next to each other -> risk of confusing intervals.\n* Phrases with quotation marks or punctuation (“в місті Києві,”) - often errors on commas.\n* ","metadata":{}},{"cell_type":"markdown","source":"## Suggest complementary metrics to capture other aspects of performance\n","metadata":{}},{"cell_type":"markdown","source":"Since the main metric is **entity-level F1**, which only takes into account exact span matches, it is useful to additionally monitor other metrics that show another side of quality:\n\n### **1. Token-level F1/Token Accuracy**\n\nMeasures quality at the level of individual tokens rather than spans.\nShows whether the model correctly finds parts of locations, even if the boundaries are not yet perfect.\n\nIt is easy to see what is happening within a sentence — whether the model is generally heading in the right direction or is completely confused.\n\n### **2. Precision/Recall at the local token level**\n\nSometimes the model is:\n\n* either too “cautious” (high precision, low recall)\n* or “aggressive” (low precision, high recall)\n\nThis helps to control the balance and avoid situations where F1 is stable but the model behaves unpredictably.\n\n### **3. Partial match/Overlap-based F1 (soft F1)**\n\nTakes into account partial matches between the predicted span and ground truth.\n\nIn Entity-Level F1, partial matches = 0.\nA \"soft F1\" will show whether at least some of the predicted names are correct.\n\n### **4. Character-level F1**\n\nAccuracy assessment at the character level.\n\nThis is especially useful for Ukrainian cases and complex names, where a difference of 1–2 characters does not mean that the model completely misunderstands the context.\n\n### **5. Exact Match Rate (EMR)**\n\nThe percentage of texts for which the model found all locations 100% correctly.\n\nThis shows “user” quality: in a real system, we are interested in cases where the model did not make any mistakes.","metadata":{}},{"cell_type":"markdown","source":"## Propose an alternative target metric, with justification.","metadata":{}},{"cell_type":"markdown","source":"### **1. Character-level F1-score (character F1)**\n\n### **Why it is the better choice:**\n\n1. **Less dependent on exact span borders.**\n   If the model shifts the border by a few characters (comma, space, case), character-F1 still records partial correctness.\n\n2. **More resistant to different tokenizers (BPE, char-level).**\n   Different word breaks do not affect the metric as much.\n\n3. **Better reflects the “quality of information.”**\n   If the model finds a partial country name (“Ukrain” instead of “Ukraine”), Entity-F1 gives a complete zero, while Character-F1 evaluates the actual progress.\n\n4. **Less penalty for boundary errors**, which are often random.\n\n5. **More fair to Ukrainian cases**, which complicate accurate span.\n\n### **2. Soft Overlap F1 (partial matching F1)**\n\nThis metric counts an entity as correct if **the overlap is greater than N%** (for example, 50%).\nThis also reduces sensitivity to boundary shifts.\n\n### Brief rationale\n\n**Character-level F1** would be a more stable and informative metric for the task of location tagging because it:\n* reduces the impact of boundary errors,\n* works better with case and punctuation,\n* adequately evaluates partially correct predictions,* is less sensitive to differences in tokenization.\n","metadata":{}},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"markdown","source":"The task already provides for an official split via the is_valid field, where:\n\nis_valid = 0 -> training data\n\nis_valid = 1 -> validation data\n\nThis is not a random split - it was formed by the authors of the dataset in order to:\n\n* maintain the same distribution of location types in train and validation;\n\n* divide sentences from one document into different parts, which prevents data leakage;\n\n* simulate the expected statistics on the test, which ensures correct correlation with the leaderboard.\n\nTherefore, using this particular split (is_valid) is the most reliable strategy, consistent with the official Kaggle evaluation.","metadata":{}},{"cell_type":"code","source":"print(\"is_valid uk_data:\")\nprint(uk_data['is_valid'].value_counts())\n\nprint(\"is_valid uk_geo_dataset parquet:\")\nprint(uk_geo_dataset['is_valid'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:36:53.488218Z","iopub.execute_input":"2025-12-09T11:36:53.488410Z","iopub.status.idle":"2025-12-09T11:36:53.508577Z","shell.execute_reply.started":"2025-12-09T11:36:53.488379Z","shell.execute_reply":"2025-12-09T11:36:53.507882Z"}},"outputs":[{"name":"stdout","text":"is_valid uk_data:\nis_valid\n0    1000000\n1      10000\nName: count, dtype: int64\nis_valid uk_geo_dataset parquet:\nis_valid\n0    1000000\n1      10000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Motivation for the chosen strategy","metadata":{}},{"cell_type":"markdown","source":"The selected split is_valid has a high correlation with Kaggle LB because:\n* it was created by the organizers specifically for the test structure;\n* train/val/test have similar distributions of texts and location types;\n* the division is made by documents -> no leakage;\n* random split or k-fold almost guarantee an overestimated CV due to repeated fragments of the same documents.\n\nConclusion:\n\nis_valid is the only strategy that gives a realistic validation score and accurately reflects the behavior of the model on Kaggle LB.","metadata":{}},{"cell_type":"code","source":"train = uk_geo_dataset[uk_geo_dataset['is_valid'] == 0] \nval = uk_geo_dataset[uk_geo_dataset['is_valid'] == 1]   \n\nprint(f\"Train: {len(train):,} samples\")\nprint(f\"Val: {len(val):,} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:37:04.713994Z","iopub.execute_input":"2025-12-09T11:37:04.714254Z","iopub.status.idle":"2025-12-09T11:37:04.779025Z","shell.execute_reply.started":"2025-12-09T11:37:04.714236Z","shell.execute_reply":"2025-12-09T11:37:04.778450Z"}},"outputs":[{"name":"stdout","text":"Train: 1,000,000 samples\nVal: 10,000 samples\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Possible reasons for low/high correlation with Kaggle LB","metadata":{}},{"cell_type":"markdown","source":"Why correlation may be low:\n\n* Data leakage in your CV if you accidentally changed the split.\n* Difference in tokenization between local code and official verification script.\n* Overfitting on validation - the model adapts to is_valid but does not generalize.\n* Different text structure in the test (longer/shorter, different types of names).\n\nWhy correlation may be high:\n* is_valid is used.\n* train/val/test have similar statistics.\n* The model is stable, without hard retraining.\n* Tokenization and post-processing are the same for CV and submission.","metadata":{}},{"cell_type":"markdown","source":"## Adversarial validation","metadata":{}},{"cell_type":"markdown","source":"Adversarial validation shows how statistically similar train and test are.\n\nThe idea is simple: we train the model to distinguish train sentences from test sentences.\n\nIf the model cannot do this, the distributions are close, and CV <-> LB will be stable.\n\nIf the model easily recognizes test, the distributions differ, and another strategy or post-processing is needed.\n\nIn this competition:\n* train and test are formed very similarly;\n* is_valid already mimics the test set;\n* the amount of data is huge — no significant shifts are expected.\n\nWhat we expect from adversarial validation:\n* ROC-AUC ≈ 0.50-0.60 -> train/test are similar\n* ROC-AUC > 0.75 -> there is a distribution shift\n* ROC-AUC ~ 0.90 -> critical shift, CV does not match LB\n\nAdversarial validation is a formal check that is_valid is a correct split.\n\nIn most official NER datasets, train/test are close, so the model's ability to distinguish between them is expected to be low (close to random guessing).","metadata":{}},{"cell_type":"code","source":"# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import roc_auc_score\n\n# train_texts = uk_data['text'].astype(str)\n# test_texts = test_data['text'].astype(str)\n\n# df_adv = pd.DataFrame({\n#     'text': pd.concat([train_texts, test_texts]),\n#     'label': [0]*len(train_texts) + [1]*len(test_texts)\n# })\n\n# tfidf = TfidfVectorizer(\n#     max_features=50000,\n#     ngram_range=(1,2)\n# )\n# X = tfidf.fit_transform(df_adv['text'])\n# y = df_adv['label']\n\n# clf = LogisticRegression(max_iter=200)\n# clf.fit(X, y)\n\n# preds = clf.predict_proba(X)[:,1]\n\n# auc = roc_auc_score(y, preds)\n# print(\"Adversarial Validation ROC-AUC:\", round(auc, 4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:47:25.703915Z","iopub.execute_input":"2025-12-09T08:47:25.704182Z","iopub.status.idle":"2025-12-09T08:48:48.535800Z","shell.execute_reply.started":"2025-12-09T08:47:25.704159Z","shell.execute_reply":"2025-12-09T08:48:48.534033Z"}},"outputs":[{"name":"stdout","text":"Adversarial Validation ROC-AUC: 0.9732\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Transformer Encoder model:","metadata":{}},{"cell_type":"code","source":"!pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:37:14.648385Z","iopub.execute_input":"2025-12-09T11:37:14.648692Z","iopub.status.idle":"2025-12-09T11:37:21.355480Z","shell.execute_reply.started":"2025-12-09T11:37:14.648672Z","shell.execute_reply":"2025-12-09T11:37:21.354769Z"}},"outputs":[{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=e7cf320bd3d352326643765cce5030ff9072d8d4a0848bd2c3f4ee621da2bd54\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# !pip uninstall -y transformers\n# !pip install transformers==4.36.0 -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:48:56.353022Z","iopub.execute_input":"2025-12-09T08:48:56.353310Z","iopub.status.idle":"2025-12-09T08:48:56.357738Z","shell.execute_reply.started":"2025-12-09T08:48:56.353284Z","shell.execute_reply":"2025-12-09T08:48:56.356761Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForTokenClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForTokenClassification,\n    EarlyStoppingCallback\n)\nfrom datasets import Dataset as HFDataset\nfrom seqeval.metrics import f1_score, precision_score, recall_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:37:21.684253Z","iopub.execute_input":"2025-12-09T11:37:21.684578Z","iopub.status.idle":"2025-12-09T11:37:53.016225Z","shell.execute_reply.started":"2025-12-09T11:37:21.684551Z","shell.execute_reply":"2025-12-09T11:37:53.015445Z"}},"outputs":[{"name":"stderr","text":"2025-12-09 11:37:35.140584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765280255.318418      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765280255.369790      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:39:55.018080Z","iopub.execute_input":"2025-12-09T11:39:55.018383Z","iopub.status.idle":"2025-12-09T11:39:55.022176Z","shell.execute_reply.started":"2025-12-09T11:39:55.018364Z","shell.execute_reply":"2025-12-09T11:39:55.021346Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"os.environ['WANDB_API_KEY'] = '6b462b2f87d400f7a62c6246ef43f027d6c8adfb'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:39:57.384806Z","iopub.execute_input":"2025-12-09T11:39:57.385563Z","iopub.status.idle":"2025-12-09T11:39:57.389029Z","shell.execute_reply.started":"2025-12-09T11:39:57.385538Z","shell.execute_reply":"2025-12-09T11:39:57.388433Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import json\n\nclass NERDataProcessor:\n    def __init__(self, tokenizer, max_length=128):\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.label2id = {'O': 0, 'LOC': 1}\n        self.id2label = {0: 'O', 1: 'LOC'}\n        self.num_labels = 2 \n    \n    def tokenize_and_encode(self, examples):\n        all_input_ids = []\n        all_attention_masks = []\n        all_labels = []\n        \n        for tokens_str, labels_str in zip(examples['tokens'], examples['labels']):\n            tokens = json.loads(tokens_str)\n            labels = json.loads(labels_str)\n            \n            encoded = self.tokenizer(\n                tokens,\n                is_split_into_words=True,\n                truncation=True,\n                padding='max_length',\n                max_length=self.max_length\n            )\n            \n            word_ids = encoded.word_ids()\n            label_ids = []\n            \n            for word_id in word_ids:\n                if word_id is None:\n                    label_ids.append(-100)\n                else:\n                    if word_id < len(labels):\n                        label_ids.append(self.label2id[labels[word_id]])\n                    else:\n                        label_ids.append(self.label2id['O'])\n            \n            all_input_ids.append(encoded['input_ids'])\n            all_attention_masks.append(encoded['attention_mask'])\n            all_labels.append(label_ids)\n        \n        return {\n            'input_ids': all_input_ids,\n            'attention_mask': all_attention_masks,\n            'labels': all_labels\n        }\n    \n    def prepare_dataset(self, df):\n        dataset = HFDataset.from_pandas(df[['tokens', 'labels']])\n        tokenized = dataset.map(\n            self.tokenize_and_encode,\n            batched=True,\n            remove_columns=dataset.column_names,\n            desc=\"Tokenizing\"\n        )\n        return tokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:42:00.335136Z","iopub.execute_input":"2025-12-09T11:42:00.335900Z","iopub.status.idle":"2025-12-09T11:42:00.343618Z","shell.execute_reply.started":"2025-12-09T11:42:00.335871Z","shell.execute_reply":"2025-12-09T11:42:00.342831Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"processor = NERDataProcessor(\n    AutoTokenizer.from_pretrained('bert-base-multilingual-cased'),\n    max_length=128\n    #max_length=256\n)\n\ntrain_dataset = processor.prepare_dataset(train)\nval_dataset = processor.prepare_dataset(val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:42:03.542150Z","iopub.execute_input":"2025-12-09T11:42:03.542457Z","iopub.status.idle":"2025-12-09T11:47:38.441181Z","shell.execute_reply.started":"2025-12-09T11:42:03.542433Z","shell.execute_reply":"2025-12-09T11:47:38.440440Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c80d08b2efa4673a630e76056a8ca9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ca5febc9b7c49f59e8b7d287f14260f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ca1188c596d4470b7ba0c6cd0ca3044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1e561a4b7b4145b2dc07cb0cebe7d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/1000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f0cc120d524dbab80ae5aa48167739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4193f114a6ca43c88b2d2f14faa3d341"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=2)\n    id2label = {0: 'O', 1: 'LOC'}\n    \n    true_labels, pred_labels = [], []\n    for pred, label in zip(predictions, labels):\n        true_seq, pred_seq = [], []\n        for p, l in zip(pred, label):\n            if l != -100:\n                true_seq.append(id2label[l])\n                pred_seq.append(id2label[p])\n        true_labels.append(true_seq)\n        pred_labels.append(pred_seq)\n    \n    return {\n        'f1': f1_score(true_labels, pred_labels),\n        'precision': precision_score(true_labels, pred_labels),\n        'recall': recall_score(true_labels, pred_labels)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:47:38.442357Z","iopub.execute_input":"2025-12-09T11:47:38.442665Z","iopub.status.idle":"2025-12-09T11:47:38.447941Z","shell.execute_reply.started":"2025-12-09T11:47:38.442647Z","shell.execute_reply":"2025-12-09T11:47:38.447316Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train_transformer_ner(model_name, train_dataset, val_dataset, run_name, config=None):\n    \n    wandb.init(\n        project='dl-assignment4-ner',\n        name=run_name,\n        config=config,\n        reinit=True\n    )\n    \n    print(f\"Training: {model_name}\")\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    label2id = {'O': 0, 'LOC': 1}\n    id2label = {0: 'O', 1: 'LOC'}\n    \n    model = AutoModelForTokenClassification.from_pretrained(\n        model_name,\n        num_labels=2,\n        id2label=id2label,\n        label2id=label2id,\n        ignore_mismatched_sizes=True\n    )\n    \n    training_args = TrainingArguments(\n        output_dir=f'./results/{run_name}',\n        num_train_epochs=config['epochs'],\n        per_device_train_batch_size=config['batch_size'],\n        per_device_eval_batch_size=config['batch_size'] * 2,\n        learning_rate=config['learning_rate'],\n        weight_decay=config['weight_decay'],\n        warmup_ratio=config['warmup_ratio'],\n        eval_strategy='epoch',\n        save_strategy='epoch',\n        load_best_model_at_end=False,\n        metric_for_best_model='f1',\n        logging_steps=50,\n        report_to='wandb',\n        fp16=torch.cuda.is_available(),\n        save_total_limit=2,\n        #lr_scheduler_type='cosine',\n        #optim='adamw_torch',\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        data_collator=DataCollatorForTokenClassification(tokenizer, padding=True),\n        compute_metrics=compute_metrics\n    )\n    \n    print(\"Starting training...\")\n    trainer.train()\n    \n    print(\"Evaluating...\")\n    results = trainer.evaluate()\n    \n    print(f\"Results:\")\n    print(f\"  F1: {results['eval_f1']:.4f}\")\n    print(f\"  Precision: {results['eval_precision']:.4f}\")\n    print(f\"  Recall: {results['eval_recall']:.4f}\")\n    \n    wandb.finish()  \n    \n    return trainer, results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:47:38.448615Z","iopub.execute_input":"2025-12-09T11:47:38.448849Z","iopub.status.idle":"2025-12-09T11:47:38.462347Z","shell.execute_reply.started":"2025-12-09T11:47:38.448832Z","shell.execute_reply":"2025-12-09T11:47:38.461772Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_sample = train.sample(n=5000, random_state=42).reset_index(drop=True)\nval_sample = val.sample(n=1000, random_state=42).reset_index(drop=True)\n\nprint(f\"Original - Train: {len(train)}, Val: {len(val)}\")\nprint(f\"Sample - Train: {len(train_sample)}, Val: {len(val_sample)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:47:49.209832Z","iopub.execute_input":"2025-12-09T11:47:49.210112Z","iopub.status.idle":"2025-12-09T11:47:49.246587Z","shell.execute_reply.started":"2025-12-09T11:47:49.210094Z","shell.execute_reply":"2025-12-09T11:47:49.245980Z"}},"outputs":[{"name":"stdout","text":"Original - Train: 1000000, Val: 10000\nSample - Train: 5000, Val: 1000\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"processor = NERDataProcessor(\n    AutoTokenizer.from_pretrained('bert-base-multilingual-cased'),\n    max_length=128\n    #max_length=256\n)\n\ntrain_dataset_small = processor.prepare_dataset(train_sample)\nval_dataset_small = processor.prepare_dataset(val_sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:47:52.785735Z","iopub.execute_input":"2025-12-09T11:47:52.786509Z","iopub.status.idle":"2025-12-09T11:47:56.240755Z","shell.execute_reply.started":"2025-12-09T11:47:52.786484Z","shell.execute_reply":"2025-12-09T11:47:56.239980Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50003b5646d423c968e047d637a04ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc9d3434266e40c7ba274303d33dd804"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"config = {\n    'batch_size': 16,\n    'learning_rate': 2e-5,\n    'epochs': 3,\n    'warmup_ratio': 0.1,\n    'weight_decay': 0.01\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:47:56.673101Z","iopub.execute_input":"2025-12-09T11:47:56.673379Z","iopub.status.idle":"2025-12-09T11:47:56.677013Z","shell.execute_reply.started":"2025-12-09T11:47:56.673361Z","shell.execute_reply":"2025-12-09T11:47:56.676439Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# trainer, results = train_transformer_ner(\n#     'bert-base-multilingual-cased',\n#     train_dataset_small,\n#     val_dataset_small,\n#     'mbert-baseline',\n#     config\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:56:08.560349Z","iopub.execute_input":"2025-12-09T08:56:08.560755Z","iopub.status.idle":"2025-12-09T08:56:08.574872Z","shell.execute_reply.started":"2025-12-09T08:56:08.560732Z","shell.execute_reply":"2025-12-09T08:56:08.573841Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Experiment with different BERT-like multilingual encoders","metadata":{}},{"cell_type":"code","source":"trainer_mbert, results_mbert = train_transformer_ner(\n    'bert-base-multilingual-cased',\n    train_dataset_small,\n    val_dataset_small,\n    'mbert-baseline',\n    config\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:48:26.466045Z","iopub.execute_input":"2025-12-09T11:48:26.466663Z","iopub.status.idle":"2025-12-09T11:52:39.365940Z","shell.execute_reply.started":"2025-12-09T11:48:26.466637Z","shell.execute_reply":"2025-12-09T11:52:39.365133Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miandroshchuk\u001b[0m (\u001b[33miandroshchuk-kse\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251209_114834-566q82f0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/566q82f0' target=\"_blank\">mbert-baseline</a></strong> to <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/566q82f0' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/566q82f0</a>"},"metadata":{}},{"name":"stdout","text":"Training: bert-base-multilingual-cased\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9454b1c4838444ba9cbce3be3ae1c188"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [939/939 03:41, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.020400</td>\n      <td>0.022375</td>\n      <td>0.828383</td>\n      <td>0.856655</td>\n      <td>0.801917</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.014500</td>\n      <td>0.024068</td>\n      <td>0.847201</td>\n      <td>0.804598</td>\n      <td>0.894569</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.004500</td>\n      <td>0.024578</td>\n      <td>0.835913</td>\n      <td>0.810811</td>\n      <td>0.862620</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Results:\n  F1: 0.8359\n  Precision: 0.8108\n  Recall: 0.8626\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁█▄▄</td></tr><tr><td>eval/loss</td><td>▁▆██</td></tr><tr><td>eval/precision</td><td>█▁▂▂</td></tr><tr><td>eval/recall</td><td>▁█▆▆</td></tr><tr><td>eval/runtime</td><td>▁▅█▆</td></tr><tr><td>eval/samples_per_second</td><td>█▄▁▃</td></tr><tr><td>eval/steps_per_second</td><td>█▄▁▃</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▄▄█▂▃▁▁▅▃▂▁▃▁▁▁▂</td></tr><tr><td>train/learning_rate</td><td>▄██▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.83591</td></tr><tr><td>eval/loss</td><td>0.02458</td></tr><tr><td>eval/precision</td><td>0.81081</td></tr><tr><td>eval/recall</td><td>0.86262</td></tr><tr><td>eval/runtime</td><td>3.7984</td></tr><tr><td>eval/samples_per_second</td><td>263.267</td></tr><tr><td>eval/steps_per_second</td><td>8.425</td></tr><tr><td>total_flos</td><td>979862837760000.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>939</td></tr><tr><td>train/grad_norm</td><td>0.33784</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0045</td></tr><tr><td>train_loss</td><td>0.02833</td></tr><tr><td>train_runtime</td><td>222.3796</td></tr><tr><td>train_samples_per_second</td><td>67.452</td></tr><tr><td>train_steps_per_second</td><td>4.223</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">mbert-baseline</strong> at: <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/566q82f0' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/566q82f0</a><br> View project at: <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251209_114834-566q82f0/logs</code>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"trainer_xlm_base, results_xlm_base = train_transformer_ner(\n    'xlm-roberta-base',\n    train_dataset_small,\n    val_dataset_small,\n    'xlm-roberta-base-baseline',\n    config\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:52:39.367010Z","iopub.execute_input":"2025-12-09T11:52:39.367215Z","iopub.status.idle":"2025-12-09T11:57:16.138616Z","shell.execute_reply.started":"2025-12-09T11:52:39.367198Z","shell.execute_reply":"2025-12-09T11:57:16.137936Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251209_115239-5jyyig5r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/5jyyig5r' target=\"_blank\">xlm-roberta-base-baseline</a></strong> to <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/5jyyig5r' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/5jyyig5r</a>"},"metadata":{}},{"name":"stdout","text":"Training: xlm-roberta-base\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db8482713ef74c028257e0da28ef37df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72229029fe41449bb0ab7cfe093b9cad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0eb82d3041e4155a33968f583f8fe93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cef7a2beab843d6bbde48f15f2cf426"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0cabfad409462ab4c3e9ff9ef6376e"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [939/939 04:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.124400</td>\n      <td>0.117202</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.116000</td>\n      <td>0.091467</td>\n      <td>0.231441</td>\n      <td>0.365517</td>\n      <td>0.169329</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.081400</td>\n      <td>0.086924</td>\n      <td>0.275194</td>\n      <td>0.349754</td>\n      <td>0.226837</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Results:\n  F1: 0.2752\n  Precision: 0.3498\n  Recall: 0.2268\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁▇██</td></tr><tr><td>eval/loss</td><td>█▂▁▁</td></tr><tr><td>eval/precision</td><td>▁███</td></tr><tr><td>eval/recall</td><td>▁▆██</td></tr><tr><td>eval/runtime</td><td>▄▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>▅█▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▅██▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▃▁▁▂▂▁▂▂▃▃▃█▆█▅▅▃▅</td></tr><tr><td>train/learning_rate</td><td>▄██▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.27519</td></tr><tr><td>eval/loss</td><td>0.08692</td></tr><tr><td>eval/precision</td><td>0.34975</td></tr><tr><td>eval/recall</td><td>0.22684</td></tr><tr><td>eval/runtime</td><td>3.8648</td></tr><tr><td>eval/samples_per_second</td><td>258.746</td></tr><tr><td>eval/steps_per_second</td><td>8.28</td></tr><tr><td>total_flos</td><td>979862837760000.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>939</td></tr><tr><td>train/grad_norm</td><td>2.22032</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0814</td></tr><tr><td>train_loss</td><td>0.13554</td></tr><tr><td>train_runtime</td><td>249.7659</td></tr><tr><td>train_samples_per_second</td><td>60.056</td></tr><tr><td>train_steps_per_second</td><td>3.76</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">xlm-roberta-base-baseline</strong> at: <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/5jyyig5r' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/5jyyig5r</a><br> View project at: <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251209_115239-5jyyig5r/logs</code>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"trainer_mdeberta, results_mdeberta = train_transformer_ner(\n    'microsoft/mdeberta-v3-base',\n    train_dataset_small,\n    val_dataset_small,\n    'mdeberta-v3-baseline',\n    config\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:59:56.625492Z","iopub.execute_input":"2025-12-09T11:59:56.625796Z","iopub.status.idle":"2025-12-09T12:00:09.725033Z","shell.execute_reply.started":"2025-12-09T11:59:56.625778Z","shell.execute_reply":"2025-12-09T12:00:09.723976Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing previous runs because reinit is set to True."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">mdeberta-v3-baseline</strong> at: <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/3lgahkd2' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/3lgahkd2</a><br> View project at: <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251209_115831-3lgahkd2/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251209_115956-mrp9mc19</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/mrp9mc19' target=\"_blank\">mdeberta-v3-baseline</a></strong> to <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/mrp9mc19' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/mrp9mc19</a>"},"metadata":{}},{"name":"stdout","text":"Training: microsoft/mdeberta-v3-base\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/55217756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer_mdeberta, results_mdeberta = train_transformer_ner(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'microsoft/mdeberta-v3-base'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset_small\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_dataset_small\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'mdeberta-v3-baseline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2400410978.py\u001b[0m in \u001b[0;36mtrain_transformer_ner\u001b[0;34m(model_name, train_dataset, val_dataset, run_name, config)\u001b[0m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     trainer = Trainer(\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;31m# Seed must be set before instantiating the model when using model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0menable_full_determinism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_determinism\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\u001b[0m in \u001b[0;36mset_seed\u001b[0;34m(seed, deterministic)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# ^^ safe to call this function even if cuda is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"# all_results = [\n#     {'model': 'mbert', 'val_f1': results_mbert['eval_f1']},\n#     {'model': 'xlm-roberta', 'val_f1': results_xlm_base['eval_f1']},\n#     {'model': 'mdeberta', 'val_f1': results_mdeberta['eval_f1']},\n# ]\n\n# results_df = pd.DataFrame(all_results)\n# print(results_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:56:08.625311Z","iopub.execute_input":"2025-12-09T08:56:08.625585Z","iopub.status.idle":"2025-12-09T08:56:08.634872Z","shell.execute_reply.started":"2025-12-09T08:56:08.625561Z","shell.execute_reply":"2025-12-09T08:56:08.633960Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## THRESHOLD","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn.functional as F\n\n# import wandb\n# wandb.init(\n#     project=\"dl-assignment4-ner\",\n#     name=\"threshold-search\",\n#     reinit=True\n# )\n\n# pred_output = trainer_mbert.predict(val_dataset_small)\n# logits = pred_output.predictions\n# label_ids = pred_output.label_ids\n\n# probs_loc = F.softmax(torch.from_numpy(logits), dim=-1)[:, :, 1].numpy()\n# def spans_from_seq(seq):\n#     spans = []\n#     start = None\n#     for i, v in enumerate(seq):\n#         if v == 1:\n#             if start is None:\n#                 start = i\n#             end = i\n#         else:\n#             if start is not None:\n#                 spans.append((start, end))\n#                 start = None\n#     if start is not None:\n#         spans.append((start, end))\n#     return spans\n\n# def entity_f1_from_probs(probs_loc, label_ids, threshold):\n#     tp = 0\n#     fp = 0\n#     fn = 0\n#     for pl, lab in zip(probs_loc, label_ids):\n#         valid_mask = lab != -100\n#         true_seq = lab[valid_mask]\n#         pred_seq = (pl[valid_mask] > threshold).astype(int)\n#         true_spans = set(spans_from_seq(true_seq))\n#         pred_spans = set(spans_from_seq(pred_seq))\n#         tp += len(true_spans & pred_spans)\n#         fp += len(pred_spans - true_spans)\n#         fn += len(true_spans - pred_spans)\n#     if tp == 0:\n#         return 0.0\n#     precision = tp / (tp + fp)\n#     recall = tp / (tp + fn)\n#     return 2 * precision * recall / (precision + recall)\n    \n# thresholds = np.linspace(0.4, 0.8, 9)\n# best_t = None\n# best_f1 = -1.0\n\n# for t in thresholds:\n#     f1 = entity_f1_from_probs(probs_loc, label_ids, t)\n#     print(\"t =\", round(t, 2), \"F1 =\", round(f1, 4))\n#     if f1 > best_f1:\n#         best_f1 = f1\n#         best_t = t\n\n# print(\"Best threshold:\", best_t, \"with F1:\", best_f1)\n\n# wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:58:05.291629Z","iopub.execute_input":"2025-12-09T11:58:05.292241Z","iopub.status.idle":"2025-12-09T11:58:11.782991Z","shell.execute_reply.started":"2025-12-09T11:58:05.292215Z","shell.execute_reply":"2025-12-09T11:58:11.781947Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251209_115805-op84y88s</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/op84y88s' target=\"_blank\">threshold-search</a></strong> to <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/op84y88s' target=\"_blank\">https://wandb.ai/iandroshchuk-kse/dl-assignment4-ner/runs/op84y88s</a>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/4037454013.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpred_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4276\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4277\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4278\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4279\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4383\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4384\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4385\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;31m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"npu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .to() doesn't accept non_blocking as kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             self.data = {\n\u001b[0m\u001b[1;32m    811\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             self.data = {\n\u001b[0;32m--> 811\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             }\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":24},{"cell_type":"markdown","source":"## Entity-Merging - вийшов провал, скіп","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoTokenizer\n# import torch\n# import torch.nn.functional as F\n# import numpy as np\n# import json\n# import pandas as pd\n# from datasets import Dataset as HFDataset\n\n# tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n\n# test_inputs = []\n# test_offset_mappings = []\n\n# for text in test_data['text']:\n#     encoded = tokenizer(\n#         text,\n#         truncation=True,\n#         padding='max_length',\n#         max_length=128,\n#         return_tensors=None,\n#         return_offsets_mapping=True  \n#     )\n    \n#     test_inputs.append({\n#         'input_ids': encoded['input_ids'],\n#         'attention_mask': encoded['attention_mask']\n#     })\n#     test_offset_mappings.append(encoded['offset_mapping'])\n\n# test_dataset = HFDataset.from_dict({\n#     'input_ids': [x['input_ids'] for x in test_inputs],\n#     'attention_mask': [x['attention_mask'] for x in test_inputs]\n# })\n\n# model = trainer_mbert.model\n# model.eval()\n\n# all_probs_loc = []\n\n# with torch.no_grad():\n#     for i in range(0, len(test_dataset), 16):\n#         batch = test_dataset[i:min(i+16, len(test_dataset))]\n\n#         input_ids = torch.tensor(batch['input_ids']).to(model.device)\n#         attention_mask = torch.tensor(batch['attention_mask']).to(model.device)\n\n#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n#         probs = F.softmax(outputs.logits, dim=-1)[:, :, 1]\n#         all_probs_loc.append(probs.cpu().numpy())\n\n# all_probs_loc = np.concatenate(all_probs_loc, axis=0)\n\n# all_locations = []\n\n# for sample_probs, offsets, text in zip(all_probs_loc, test_offset_mappings, test_data['text']):\n#     location_spans = []\n#     current_start = None\n\n#     for p_loc, (start, end) in zip(sample_probs, offsets):\n#         if start == 0 and end == 0:\n#             continue\n\n#         is_loc = p_loc > best_t\n\n#         if is_loc:\n#             if current_start is None:\n#                 current_start = start\n#             current_end = end\n#         else:\n#             if current_start is not None:\n#                 location_spans.append((current_start, current_end))\n#                 current_start = None\n    \n#     if current_start is not None:\n#         location_spans.append((current_start, current_end))\n\n#     location_texts = [text[s:e].strip() for s, e in location_spans]\n#     location_texts = [loc for loc in location_texts if loc]\n\n#     all_locations.append(location_texts)\n\n# submission = pd.DataFrame({\n#     \"text_id\": test_data[\"text_id\"],\n#     \"locations\": [json.dumps(locs, ensure_ascii=False) for locs in all_locations]\n# })\n\n# submission.to_csv('submission_threshold_50-10_16_5.csv', index=False)\n\n# print(\"Submission with threshold saved!\")\n# print(submission.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:56:08.652454Z","iopub.execute_input":"2025-12-09T08:56:08.652903Z","iopub.status.idle":"2025-12-09T08:56:08.670964Z","shell.execute_reply.started":"2025-12-09T08:56:08.652878Z","shell.execute_reply":"2025-12-09T08:56:08.669971Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"p1 = trainer_mbert.predict(val_dataset_small)\np2 = trainer_xlm.predict(val_dataset_small)\np3 = trainer_mdeberta.predict(val_dataset_small)\n\nprobs = (\n    F.softmax(torch.from_numpy(p1.predictions), dim=-1) + \n    F.softmax(torch.from_numpy(p2.predictions), dim=-1) + \n    F.softmax(torch.from_numpy(p3.predictions), dim=-1)\n) / 3\n\npreds = np.argmax(probs.numpy(), axis=-1)\n\nid2label = {0: 'O', 1: 'LOC'}\ntrue_labels, pred_labels = [], []\n\nfor pred, label in zip(preds, p1.label_ids):\n    true_seq, pred_seq = [], []\n    for p, l in zip(pred, label):\n        if l != -100:\n            true_seq.append(id2label[l])\n            pred_seq.append(id2label[p])\n    if true_seq:\n        true_labels.append(true_seq)\n        pred_labels.append(pred_seq)\n\nensemble_f1 = f1_score(true_labels, pred_labels)\n\nprint(f\"mBERT:    {results_mbert['eval_f1']:.4f}\")\nprint(f\"XLM-R:    {results_xlm['eval_f1']:.4f}\")\nprint(f\"DeBERTa:  {results_mdeberta['eval_f1']:.4f}\")\nprint(f\"ENSEMBLE: {ensemble_f1:.4f}\")\nprint(f\"+{ensemble_f1 - max(results_mbert['eval_f1'], results_xlm['eval_f1'], results_mdeberta['eval_f1']):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:56:08.672044Z","iopub.execute_input":"2025-12-09T08:56:08.672405Z","iopub.status.idle":"2025-12-09T08:56:08.725762Z","shell.execute_reply.started":"2025-12-09T08:56:08.672376Z","shell.execute_reply":"2025-12-09T08:56:08.724640Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2987187632.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_xlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_mdeberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m probs = (\n","\u001b[0;31mNameError\u001b[0m: name 'trainer_mbert' is not defined"],"ename":"NameError","evalue":"name 'trainer_mbert' is not defined","output_type":"error"}],"execution_count":31}]}